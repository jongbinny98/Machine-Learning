{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jongbinny98/ucsc/blob/master/final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NegAkmLZKITL"
      },
      "source": [
        "# CSE - 144 Assignment 4\n",
        "\n",
        "## Due: June 7, 2022 11:59 pm\n",
        "\n",
        "\n",
        "**Be sure to set your Runtime environment to include a GPU, as it will speed up the training considerably (this time that's important!).**\n",
        "\n",
        "Intro Slides: https://docs.google.com/presentation/d/1PjqwL9g8XPr40LLRjRAAtxzc4Tf9iqVVnq61gJ59_Iw/edit?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9XMaBDrqJAzi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e344900-a60a-455a-a189-655ab00694a1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "UQ7vc7_hKITR"
      },
      "outputs": [],
      "source": [
        "# Ignore the warnings - Otherwise, TensorFlow tends to innundate one with far too many warnings.\n",
        "import warnings\n",
        "warnings.filterwarnings('always')\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Data visualizaton.\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import seaborn as sns\n",
        "import random as rn\n",
        "\n",
        "# Configure some defaults.\n",
        "%matplotlib inline  \n",
        "style.use('fivethirtyeight')\n",
        "sns.set(style='whitegrid',color_codes=True)\n",
        "\n",
        "# ML + Deep Learning Imports\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "from tensorflow import keras\n",
        "from keras.regularizers import l2\n",
        "from keras.preprocessing.image import ImageDataGenerator # Data Augmentation\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import datasets, layers, models \n",
        "from keras.layers.advanced_activations import PReLU\n",
        "from tensorflow.keras.models import Sequential # This building the models\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, SGD, Adagrad, Adadelta, RMSprop \n",
        "from tensorflow.keras.utils import to_categorical # if label is 0,1,...,99 etc then it becomes [0,...1,.,0] a len 100 vector\n",
        "from keras.callbacks import ReduceLROnPlateau #learning rate decay policy\n",
        "from sklearn.model_selection import train_test_split # for splitting data\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd # for making our csv\n",
        "import time\n",
        "# Image preprocessing and reading in.\n",
        "import imageio \n",
        "from pathlib import Path\n",
        "import os, sys\n",
        "from zipfile import ZipFile\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVLfTcsJKITR"
      },
      "source": [
        "#### Step-0: Import dataset\n",
        "Download Tiny-ImageNet-100 dataset using the code blocks below. \n",
        "\n",
        "Please fill in the code block below to split the data into training, validation and test datasets you may use scikit-learn to split."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Tiny-Imagenet-100\n",
        "!gdown 1bn9RtCsMu-v_ZagKCK2z7hVEDOIjb9Pd\n",
        "\n",
        "for file in os.listdir(os.getcwd()):\n",
        "    if file.endswith(\".zip\"):\n",
        "        zip = ZipFile(file)\n",
        "        zip.extractall()\n",
        "    else:\n",
        "        print(\"not found\")"
      ],
      "metadata": {
        "id": "Rp7dVNpkfC3_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29340f2b-57dc-4668-c754-a9c4295a7488"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1bn9RtCsMu-v_ZagKCK2z7hVEDOIjb9Pd\n",
            "To: /content/tiny-image-net-100.zip\n",
            "100% 139M/139M [00:00<00:00, 274MB/s]\n",
            "not found\n",
            "not found\n",
            "not found\n",
            "not found\n",
            "not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'tiny-image-net-100/'\n",
        "\n",
        "def get_id_dictionary():\n",
        "    \"\"\"\n",
        "    Maps each class id to an unique integer.\n",
        "    \"\"\"\n",
        "    id_dict = {}\n",
        "    for i, line in enumerate(open(path + 'wnids.txt', 'r')):\n",
        "        id_dict[line.rstrip('\\n')] = i\n",
        "    return id_dict\n",
        "  \n",
        "def get_class_to_id_dict():\n",
        "    \"\"\"\n",
        "    Maps each class id to the English version of the label.\n",
        "    \"\"\"\n",
        "    id_dict = get_id_dictionary()\n",
        "    all_classes = {}\n",
        "    result = {}\n",
        "    for i, line in enumerate(open( path + 'words.txt', 'r')):\n",
        "        n_id, word = line.split('\\t')[:2]\n",
        "        all_classes[n_id] = word\n",
        "    for key, value in id_dict.items():\n",
        "        result[value] = (key, all_classes[key])      \n",
        "    return result\n",
        "\n",
        "def get_data(id_dict, n_samples = 500):\n",
        "    \"\"\"\n",
        "    n_samples: number of samples per class. n_samples has a max of 500.\n",
        "    The range is [1, 500].\n",
        "    \"\"\"\n",
        "    print('starting loading data')\n",
        "    train_data, test_data = [], []\n",
        "    train_labels = []\n",
        "    t = time.time()\n",
        "    for key, value in id_dict.items():\n",
        "      if value<100: # Only focus on first 100 classes\n",
        "        train_data += [imageio.imread( path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), pilmode='RGB') for i in range(n_samples)]\n",
        "        train_labels_ = np.array([[0]*100]*n_samples)\n",
        "        train_labels_[:, value] = 1\n",
        "        train_labels += train_labels_.tolist()\n",
        "\n",
        "    test_image_names = []\n",
        "    path_list = list(Path(path+'test/images/').glob('*.jpg'))\n",
        "    for test_image_path in path_list:\n",
        "        img_name = str(test_image_path).split('.')[0][-18:]\n",
        "        test_image_names.append(img_name)\n",
        "        test_data.append(imageio.imread(test_image_path , pilmode='RGB'))\n",
        "        \n",
        "    print('finished loading data, in {} seconds'.format(time.time() - t))\n",
        "\n",
        "    train_data = np.array(train_data)\n",
        "    train_labels = np.array(train_labels)\n",
        "    test_data = np.array(test_data)\n",
        "\n",
        "    return train_data, train_labels, test_data, test_image_names"
      ],
      "metadata": {
        "id": "MItoUh2LZSsX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "K6PznhssKITR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46c81c94-dca2-487f-a3bb-fb6bd8082370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting loading data\n",
            "finished loading data, in 23.20013952255249 seconds\n",
            "train data shape:  (45000, 64, 64, 3)\n",
            "train label shape:  (45000, 100)\n",
            "val data shape:  (5000, 64, 64, 3)\n",
            "val label shape:  (5000, 100)\n",
            "test data shape:  (5000, 64, 64, 3)\n"
          ]
        }
      ],
      "source": [
        "###### Your codes start here.######\n",
        "\n",
        "# Start with n_samples = 10 to get your code working and then increase accordlingy.\n",
        "id_dict = get_id_dictionary()\n",
        "train_data, train_labels, test_data, test_image_names = get_data(id_dict)\n",
        "x_test, test_size = test_data, 0.1\n",
        "x_train, x_val, y_train, y_val = train_test_split(train_data, train_labels, test_size = test_size)\n",
        "\n",
        "\n",
        "###### Your codes end here.######\n",
        "print( \"train data shape: \",  x_train.shape )\n",
        "print( \"train label shape: \", y_train.shape )\n",
        "print( \"val data shape: \",  x_val.shape )\n",
        "print( \"val label shape: \", y_val.shape )\n",
        "print( \"test data shape: \",   x_test.shape )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's set some random seeds to make this more reproducible.\n",
        "def setseeds():\n",
        "  np.random.seed(137)\n",
        "  rn.seed(137)\n",
        "  tf.random.set_seed(137)\n",
        "setseeds()"
      ],
      "metadata": {
        "id": "nSrUa9R4iUU6"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step-1: Data Preparation & Exploration\n",
        "\n",
        "Let's take a look at a few of these images. Rerun this cell multiple times to see different images for each class.\n",
        "\n",
        "You may notice that these images look low fidelity, which is because they are! As we increase our image size, we also increase our model complexity. What's important is that our classes are still distinguishable from each other."
      ],
      "metadata": {
        "id": "PJvMZiSoprph"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "d45hvQNDKITS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "243c444d-dffe-4893-c9dd-b49cfebc730d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa49c600e90>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Visulize one image from Tiny-ImageNet\n",
        "plt.imshow(x_train[0], cmap=plt.cm.binary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFpoh2XBKITT"
      },
      "source": [
        "#### Step-2: Build a neural network.\n",
        "Build your convolutional neural networks by adding some layers. You should use 2 convolution layers and ReLU as the default activation function.\n",
        "Add max pooling after the first layer.\n",
        "The kernel size of both layers should be 3x3. Use 32 and 64 as the number of filters for the first and the second convolutional layers, respectively. After that, flatten your input and add two more dense layers. There should be 1024 units in the first dense with ReLU activation, and use 100 hidden units in the second dense layer with softmax activation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build convolutional neural network\n",
        "###### Normalizing. ######\n",
        "x_train = x_train / 255.0\n",
        "x_val = x_val / 255.0\n",
        "# x_test = x_test / 255.0\n",
        "\n",
        "# resModel = keras.applications.ResNet50(include_top=False,\n",
        "#                                        weights=\"imagenet\",\n",
        "#                                        input_shape=(224, 224, 3))\n"
      ],
      "metadata": {
        "id": "_qZrWN65ZbF1"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Y-7IE80mKITT"
      },
      "outputs": [],
      "source": [
        "###### Your code starts here. ######\n",
        "#define our CNN architecture, using karas\n",
        "# This is where we define the architecture of our deep neural network.\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters = 32,      \n",
        "                 kernel_size = (3, 3), \n",
        "                 activation = PReLU()\n",
        "                 ))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters = 64,      \n",
        "                 kernel_size = (3, 3), \n",
        "                 activation = PReLU()\n",
        "                 ))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(1024, activation = 'relu'))  \n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(100, activation = \"softmax\"))\n",
        "\n",
        "###### Your codes end here.######"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Side Note: How to save a model to google drive\n"
      ],
      "metadata": {
        "id": "-KmndNeeHHD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount colab to your drive\n",
        "# from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "iMzmHqxtHGgX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "200e5424-1173-4f63-d257-da6c1d350362"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add load model if exists"
      ],
      "metadata": {
        "id": "wD22-ZNKHjdz"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save your model to gdrive\n",
        "# model.save('/content/drive/My Drive/hw4 kaggle/hw4_model.h5')  "
      ],
      "metadata": {
        "id": "VnMotv2THOJL"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load a model\n",
        "# Returns a compiled model identical to the previous one, if you load you don't need to model.compile()\n",
        "# model = load_model('/content/drive/My Drive/hw4 kaggle/hw4_model.h5') "
      ],
      "metadata": {
        "id": "AOh-RFyyHYgg"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt27nBzJKITU"
      },
      "source": [
        "#### Step-3: Train the model\n",
        "Compile model here and set your initial hyperparameters. Use ADAM as the optimizer. You should choose 'categorical_crossentropy' as your loss function, and the metrics should be 'accuracy'. After that, train your model for 30 epochs. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-3)\n",
        "model.build(input_shape=(None, 64, 64, 3))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Vow_Wly8N_AD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32ec96f4-ad16-479b-e343-390930c10e40"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 62, 62, 32)        123904    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 31, 31, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 31, 31, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 29, 29, 64)        72320     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 12544)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1024)              12846080  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 100)               102500    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,144,932\n",
            "Trainable params: 13,144,868\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Your code here###\n",
        "#compile the model\n",
        "model.compile(optimizer = Adam(lr = 0.001),\n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "# model.compile(optimizer='adam',\n",
        "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#               metrics=['accuracy'])\n",
        "### Your code here###"
      ],
      "metadata": {
        "id": "pEyagpLSMLtq"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Augmentation\n",
        "\n",
        "There are many augmentations you can use! Read about them in the Keras documentation.\n",
        "\n",
        " **Rescale is very important!**"
      ],
      "metadata": {
        "id": "1PldpcYoHsG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up data generators for training and validation set\n",
        "# add transformations\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "          rescale=1/255.,\n",
        "          featurewise_center=False,           # set input mean to 0 over the dataset\n",
        "          samplewise_center=False,            # set each sample mean to 0\n",
        "          featurewise_std_normalization=False,# divide inputs by std of the dataset\n",
        "          samplewise_std_normalization=False, # divide each input by its std\n",
        "          zca_whitening=False,                # apply ZCA whitening\n",
        "          rotation_range=0,                   # randomly rotate images in the range (degrees, 0 to 180)\n",
        "          width_shift_range=0.1,              # randomly shift images horizontally (fraction of total width)\n",
        "          height_shift_range=0.1,             # randomly shift images vertically (fraction of total height)\n",
        "          horizontal_flip=True,               # randomly flip images\n",
        "          vertical_flip=True)               # randomly flip images\n",
        "\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1/255.)"
      ],
      "metadata": {
        "id": "YenY_mK3LOmp"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Your code here ###\n",
        "\n",
        "# fit generators to datasets\n",
        "\n",
        "### Your code here###"
      ],
      "metadata": {
        "id": "JLAj2KeOLuR1"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Your Code Here ###\n",
        "\n",
        "#set number of epochs, set batch_size\n",
        "nb_epoch = 20\n",
        "batch_size= 64\n",
        "\n",
        "# # Fit the model on the batches generated by datagen.flow().\n",
        "# setseeds()\n",
        "\n",
        "# history = model.fit(x_train, y_train,\n",
        "#                     batch_size = batch_size,\n",
        "#                     epochs = nb_epoch, \n",
        "#                     validation_data = (x_val, y_val)\n",
        "#                     )\n",
        "\n",
        "history = model.fit(datagen.flow(x_train,y_train,\n",
        "                                       batch_size=batch_size, \n",
        "                                       seed=27,\n",
        "                                       shuffle=False),\n",
        "                    epochs=nb_epoch,\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                    validation_data=(x_val,y_val),\n",
        "                    verbose=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "1I6RSsDML98I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "35c7703a-78a5-4540-b85a-eedff52107fa"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "273/703 [==========>...................] - ETA: 33s - loss: 4.3865 - accuracy: 0.0388"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-2bb9a19845ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Model Performance"
      ],
      "metadata": {
        "id": "7umFV7g_rUqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Model Performance\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "def plot_data(history):\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('Model Loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend(['train', 'test'])\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('Model Accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend(['train', 'test'])\n",
        "  plt.show()\n",
        "\n",
        "plot_data(history)"
      ],
      "metadata": {
        "id": "jUmhu6zyrXKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_val, batch_size=32)\n",
        "y_test = np.argmax(predictions, axis=1)\n",
        "model.evaluate(x_val, y_val)"
      ],
      "metadata": {
        "id": "BkMG2kVwbmo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Submission Kaggle File\n",
        "def create_submission_file(model):\n",
        "  name2idx = {}\n",
        "  sample_submission = pd.read_csv('tiny-image-net-100/submission_sample.csv')\n",
        "  filename_order = sample_submission['img_id'].values\n",
        "  for i in range(len(filename_order)):\n",
        "    name2idx[filename_order[i]] = i\n",
        "\n",
        "  # Google colab reads the files in a different order than the answer file was created.\n",
        "  # This is done to preserve the file order.\n",
        "  result_dict = {'img_id': [None]*len(x_test),\n",
        "                'label':[None]*len(x_test)}\n",
        "  test_preds = np.argmax(model.predict(x_test/255.),axis=-1)\n",
        "\n",
        "  for i in range(len(test_image_names)):\n",
        "    test_image_name = test_image_names[i]\n",
        "    result_dict['img_id'][name2idx[test_image_name]] = test_image_name\n",
        "    result_dict['label'][name2idx[test_image_name]] = test_preds[i]\n",
        "\n",
        "  pd.DataFrame(result_dict).to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "be60AJz3dbm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create your submission file and download it.\n",
        "## Your Code Here ###"
      ],
      "metadata": {
        "id": "01m0eGmqdyAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You made it this far! You may have noticed your accuracy is not that great to improve on it do the following:\n",
        "\n",
        "i) Design a more complex neural network architecture. (Transfer learning may help)\n",
        "\n",
        "ii) Utilize data augmentation during training.\n",
        "\n",
        "\n",
        "Experiment often and save your models. \n",
        "\n",
        "When you are satisfied submit your predictions to Kaggle. \n",
        "\n",
        "Good luck!"
      ],
      "metadata": {
        "id": "CLtbnfbtx078"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "final project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "3afe1e4ce7822ba0e325ee279bb4d100dadd903c2abe2139ffec7391692aa1eb"
    },
    "kernelspec": {
      "display_name": "Python 3.6.13 ('zichao')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "orig_nbformat": 4,
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}